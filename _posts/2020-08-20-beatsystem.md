---
layout: post
project: "beatscape"
title: "Dynamic Music System"
long-title: "Synchronizing the World to Musical Cues"
date: 2020-08-20
date-path: "2020/08/20"
author: "Nathan Jew"
youtubeId:
noise-images:
- filename: "rawNoise.png"
  caption: "Raw perlin noise is too smooth on its own to look realistic."
- filename: "layeredNoise.png"
  caption: "However if you layer it on top of itself at different scales and intensities, it emulates rocky terrain."
hill-noise-images:
- filename: "topViewHillMask.png"
  caption: "The hill mask made up of large scale noise with a cutoff value to create large black areas and normalized back to a range of 0 to 1."
- filename: "topViewDetails.png"
  caption: "A more fine heightmap which will add details to the hills to make them less smooth."
border-noise-images:
- filename: "topViewBorderFalloff.png"
  caption: "The falloff map. Generated by assinging a value to each pixel based on a square distance to the center of the map."
- filename: "topViewBorderHills.png"
  caption: "The border hills heightmap. Used to break up the uniformity of the falloff."
result-images:
- filename: "topViewFinal.png"
  caption: "The final heightmap."
- filename: "topViewFinalTerrain.png"
  caption: "Top view of the terrain generated from the heightmap"
landscape-images-1:
- filename: "landscape0.png"
- filename: "landscape2.png"
- filename: "landscape3.png"
- filename: "landscape1.png"
---

{% include post-gallery.html set=page.landscape-images-1 %}

# Introduction
As a slightly above average programmer and a slightly below average musician, I find myself fascinated by the potential offered by dynamic music in video games. Really, the coolest and most immersive tracks are the ones that actually react to and evolve with the game, instead of just being a passive background loop. But that's something that you can really only pull off with a combination of good support in code and cleverly composed music. Which, in theory, is something I'm in a position to maybe half pull off.

So naturally, to test the limits of this idea, we decided to make an entire game around it!

# Humble Beginnings
Now, this didn't come from nowhere. In fact, it's something we had been attempting in our previous VR titles (though on a smaller scale), since in VR, it's important to try and use every element of the medium available - including audio cues. So, in both Asteroid Escape and Overboard, we used pseudo-dynamic music tracks to indicate the current "intensity" level, which ended up being my most noticeable contribution to those projects, while Jack focused his efforts on more visual and gameplay elements.

To accomplish this, I used a "layering" technique, where once I had a completed song, I'd export each of the core instruments as a separate track, so that each could be faded in and out independently to alter the musical atmosphere. And in each game, there were certain tradeoffs that served as important lessons for what would eventually become Beatscape.

# Music In Asteroid Escape
In Asteroid Escape, we only had 4 tracks in a single loop, where each new layer was simply added on top the existing instruments (no replacement or transitions needed). This sort of worked because the base elements were static enough to not come across as too repetitive (I find that putting too much progression into a short loop gets annoying way faster), and because each individual track occupied its own space that didn't clash with other tracks as more were added.

The final result was a simple but effective background track that could quickly react to the game's changing circumstances.

The problem with this system was that all of the loops were technically playing at all times to ensure that they were always synchronized - even if most of them were silent. Sure, this was the simplest solution, but if there were theoretically even more layers, it could result in desyncing problems, or just waste audio resources.

# Music In Overboard
In Overboard, I used the same strategy of exporting each layer of the music, but this time, I improved it by using a "queue" system, so that tracks could signal the music system to start/stop playing for specific events. The music system would then find the nearest downbeat (i.e. the start of the next loop), and then play the track accordingly so that it would be perfectly synchronized and in time.

As such, Overboard's music had much more variety, and musically, it meant that while the main section had no musical "movement" (it stays on the same chord the whole time), I could cue "solo" sections to prevent the music from getting too boring.

But even this had its flaws, especially because waiting for the next downbeat often meant waiting for an indeterminate amount of time. This meant that if an intense section was meant to line up with a shark attack, chances were that it would end up being way too late, and the player would not make the intended connection.

On top of that, even a small bit of lag or a bad set of starting conditions could send the whole system into a chaotic discordant mess. Relying on Unity's 'WaitForSeconds' call just wasn't going to cut it if we ever wanted high precision, say, for a rhythm based game.

# Finding A Better Way
Enter Beatscape, a game so closely tied to the soundtrack that we had no choice but to prioritize the music system before basically everything else. This meant there was no way we could rely on the flimsy systems from Asteroid Escape or Overboard - effective as they may have been for their respective needs.

From the start, we had a very clear vision of two things:
1. The world should react to the music, either by having things pulse on beat or align themselves positionally with the rhythm.
2. The player should be able to trigger special effects if they attack on beat, which should also change the music.

And both of these required that there be a direct correspondence between internal beats in a track and in-game events, which we just didn't have support for. In our previous systems, once the music started, there was no way of knowing where you were in the song. It relied entirely on loops having the same fixed duration, so that they could be layered on top of each other without issue.

# Finding The Beat
I began by changing the system from being centered around track length to being centered around beat length, since the beat is what defines the rhythm and therefore when the world should react. And a big part of this is knowing the track's **time signature**, which tells you how many beats you have per bar.

Usually, you'll have 4 beats per bar, but there's really no reason why you can't have any other number. Bars in this sample are divided by vertical lines, and they typically represent how spaced out your "strong" beats are.

However, in Beatscape, we took this a step further by specifying custom "strong" beats for each track. This, in a sense, corresponded to the pattern that the player was expected to replicate.

The next secret came from 

# Timing
Next, we needed a reliable way of ensuring that events could occur on the beat, and with arbitrarily precise timing. For example, if a sword swing had an audio cue, that audio cue needed to be exactly on the beat, and we wouldn't be able to predict whether to play this sound far in advance like Overboard because the player is acting and expecting feedback in real-time.

The solution was two-fold. Firstly, we designed every event

in a way that Overboard's music system wouldn't be able to handle.



The reason this was important is because the world of Beatscape operates under a few

You could argue that tempo is the only parameter we need, but because strong beats in Beatscape are still important, and because we ended up using repeated patterns of notes per bar (more on that in a bit), it was helpful to have both. Plus, it's much nicer to measure a track length in how many bars there are (which is almost always a multiple of 4), rather than how many beats there are.

From there, you've got your final calculation:
```
beatLength = trackLength / numBars / beatsPerBar
```

```
newValue = (sourceValue * (1 - additionPower) + additionValue * additionPower) * sourceValue
```

where the source is the hill mask and the addition is the detail heightmap. This function averages the two with a variable power, perfect for adding details without overpowering the hill mask.

# Creating Mountainous Borders
To create borders, I knew I needed to use a falloff map to encourage the terrain to be higher around the edges of the map. The main problem with directly increasing the height of the terrain near the borders is that it will look far too unnatural. Therefore, we need to combine the uniform falloff with noise. While I admit the final result isn't perfect, it fullfilled its purpose.

{% include post-gallery.html set=page.border-noise-images %}

Admittedly it took me a while to figure out the best way to combine these two heightmaps. However, I eventaully settled on simply multiplying them together:

```
newValue = sourceValue * additionValue
```

I then combined this new border hills heightmap with the previously generated hills heightmap with simple max function:

```
newValue = Max(sourceValue, additionValue)
```

# Create Terraces
I knew our soldiers would have trouble climbing mountains, but still wanted them to be able to navigate and fight on them. Luckily, deserts commonly have plateaus so it made sense to terrace the terrain.

To add terraces we need to flatten a range of height values. This requires a bit of math as simply rounding height values to the nearest terrace height would look completely unnatural. However, I created the following function to do it:

```
if (sourceVal > terraceHeight) {
    newValue = (soureVal - terracePull) / (1f - terracePull)
    if (newValue < terraceHeight) newValue = terraceHeight
}
```

The function recieves a height to flatten at and a pull value which is the amount of terrain above it that should be pulled down and flattened. In order to maintain the same original height for the terrain after it gets lowered, we have to scale up the lowered terrain vertically.

# The Result
{% include post-gallery.html set=page.result-images %}

# Layering Visualized
{% include mp4-video.html path="blog/2020/08/12/terrainShowcase" %}

# Conclusion
While there are certainly improvements I can make to the terrain generation, it serves its purpose well. Though I only demonstrated how layering noise can be used to create stylized desert enviornments, the techniques shown above can be used anywhere with a little tweaking and imagination.

To explore the code or use it in your own project, [checkout the GitHub repository.](https://github.com/jacksouthard/LayeredHeightmapTerrain)
